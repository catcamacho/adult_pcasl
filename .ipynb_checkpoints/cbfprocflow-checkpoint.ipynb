{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces.utility import Function, IdentityInterface\n",
    "from nipype.interfaces.io import FreeSurferSource, SelectFiles, DataSink\n",
    "from nipype.pipeline.engine import Workflow, Node\n",
    "\n",
    "from nipype.interfaces.freesurfer import Binarize, MRIConvert, FSCommand\n",
    "from nipype.interfaces.fsl import ApplyMask, Reorient2Std\n",
    "from nipype.interfaces.fsl.preprocess import MCFLIRT, SliceTimer, FLIRT, FAST\n",
    "from nipype.algorithms.rapidart import ArtifactDetect\n",
    "from nipype.interfaces.fsl.model import GLM\n",
    "from nipype.algorithms.confounds import CompCor\n",
    "\n",
    "# MATLAB setup - Specify path to current SPM and the MATLAB's default mode\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('~/spm12/toolbox')\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "\n",
    "#other study-specific variables\n",
    "project_home = '/Users/myelin/Dropbox/Projects/TH_NAR_ASL/proc'\n",
    "raw_dir = project_home + '/raw'\n",
    "subjects_list = open(project_home + '/misc/subjects.txt').read().splitlines()\n",
    "output_dir = project_home + '/proc'\n",
    "wkflow_dir = project_home + '/workflows'\n",
    "template = project_home + '/template/MNI152_T1_2mm_brain.nii'\n",
    "gray_matter_mask = project_home + '/template/MNI152_T1_2mm_graymatter.nii'\n",
    "\n",
    "#freesurfer setup\n",
    "subjects_dir = project_home + '/freesurfer'\n",
    "FSCommand.set_default_subjects_dir(fs_dir)\n",
    "\n",
    "#Population specific variables for ASL\n",
    "nex_asl = 3 #number of excitations from the 3D ASL scan parameters\n",
    "inversion_efficiency = 0.8 #from GE\n",
    "background_supp_eff = 0.75 #from GE\n",
    "efficiency = inversion_efficiency * background_supp_eff \n",
    "T1_blood = 1.6 #T1 of blood in seconds(1.6s at 3T and 1.4s at 1.5T)\n",
    "sat_time = 2 #in seconds, from GE\n",
    "partition_coeff = 0.9 #whole brain average in ml/g\n",
    "scaling_factor = 32 #scaling factor, can be taken from PW dicom header at position 0043,107f (corresponds to #coils?)\n",
    "postlabel_delay = 1.525 #post label delay in seconds\n",
    "labeling_time = 1.450 #labeling time in seconds\n",
    "T1_tissue = 1.2 #estimated T1 of grey matter in seconds\n",
    "TR = 4.844 #repetition time\n",
    "\n",
    "# Study variables for resting state processing\n",
    "rest_TR = 2 #in seconds\n",
    "num_slices = 29\n",
    "slice_direction = 3 #3 = z direction\n",
    "interleaved = True\n",
    "#all rates are in Hz (1/TR or samples/second)\n",
    "highpass_freq = 0.008 #in Hz\n",
    "lowpass_freq = 0.09 #in Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## File handling nodes\n",
    "\n",
    "# Select subjects\n",
    "infosource = Node(IdentityInterface(fields=['subjid']),\n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subjects_list)]\n",
    "\n",
    "# SelectFiles\n",
    "templates = {'pw_volume': raw_dir + '/{subjid}/pw.nii',\n",
    "             'pd_volume': raw_dir + '/{subjid}/pd.nii', \n",
    "             'rest': raw_dir + '/{subjid}/rest_raw.nii'}\n",
    "selectfiles = Node(SelectFiles(templates), name='selectfiles')\n",
    "\n",
    "# FreeSurferSource - Data grabber specific for FreeSurfer data\n",
    "fssource = Node(FreeSurferSource(subjects_dir=subjects_dir),\n",
    "                run_without_submitting=True,\n",
    "                name='fssource')\n",
    "# Datasink\n",
    "datasink = Node(DataSink(base_directory = output_dir, \n",
    "                         container = output_dir), \n",
    "                name='datasink')\n",
    "\n",
    "# DataSink output substitutions (for ease of folder naming)\n",
    "substitutions = [('_subjid_', '')]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## File Processing nodes\n",
    "\n",
    "# convert files to nifti\n",
    "mri_convert = Node(MRIConvert(out_type='nii',\n",
    "                              out_orientation='RAS',\n",
    "                              conform_size=2,\n",
    "                              crop_size= (128, 128, 128)), \n",
    "                   name='mri_convert')\n",
    "\n",
    "# reorient data for consistency\n",
    "reorient_anat = Node(Reorient2Std(output_type='NIFTI'),\n",
    "                     name='reorient_anat')\n",
    "\n",
    "# reorient PD data for consistency\n",
    "reorient_pd = Node(Reorient2Std(output_type='NIFTI'),\n",
    "                   name='reorient_pd')\n",
    "\n",
    "reorient_pw = Node(Reorient2Std(output_type='NIFTI'),\n",
    "                   name='reorient_pw')\n",
    "\n",
    "# Register subject's anatomy to the template\n",
    "linearReg = Node(FLIRT(output_type='NIFTI'),\n",
    "                 name='linearReg')\n",
    "\n",
    "# Binarize -  binarize and dilate image to create a brainmask\n",
    "binarize = Node(Binarize(min=0.5,\n",
    "                         max=300,\n",
    "                         dilate=3,,\n",
    "                         erode=2,\n",
    "                         out_type='nii'),\n",
    "                name='binarize')\n",
    "\n",
    "# Mask brain in pw volume\n",
    "applyMask_pw = Node(ApplyMask(output_type='NIFTI'),\n",
    "                    name='applyMask_pw')\n",
    "\n",
    "# Mask brain pd volumes\n",
    "applyMask_pd = Node(ApplyMask(output_type='NIFTI'), \n",
    "                    name='applyMask_pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Custom functions\n",
    "#quantify CBF from PW volume (Alsop MRIM 2015 method)\n",
    "def quantify_cbf_alsop(pw_volume,pd_volume,sat_time,postlabel_delay,T1_blood,labeling_time,efficiency,partition_coeff,TR,T1_tissue,scaling_factor,nex_asl):\n",
    "    import os\n",
    "    import nibabel as nib\n",
    "    from numpy import exp\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    # set variables\n",
    "    pw_nifti1 = nib.load(pw_volume)\n",
    "    pw_data = pw_nifti1.get_data()\n",
    "    pw_data = pw_data.astype(float)\n",
    "    pd_nifti1 = nib.load(pd_volume)\n",
    "    pd_data = pd_nifti1.get_data()\n",
    "    pd_data = pd_data.astype(float)\n",
    "    conversion = 6000 #to convert values from mL/g/s to mL/100g/min\n",
    "    pd_factor = 1/(1-exp((-1*TR)/T1_tissue))\n",
    "    \n",
    "    cbf_numerator = conversion*partition_coeff*pw_data*exp(postlabel_delay/T1_blood)\n",
    "    cbf_denominator = sat_time*efficiency*T1_blood*scaling_factor*nex_asl*pd_data*pd_factor*(1-exp((-1*labeling_time)/T1_blood))\n",
    "    cbf_data = cbf_numerator/cbf_denominator\n",
    "    \n",
    "    cbf_volume = nib.Nifti1Image(cbf_data, pw_nifti1.affine)\n",
    "    nib.save(cbf_volume, 'alsop_cbf.nii')\n",
    "    cbf_path = os.path.abspath('alsop_cbf.nii')\n",
    "    return cbf_path\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Normalizing data for first and second level analysis\n",
    "\n",
    "# Register subject's anatomy to the template\n",
    "linearReg = Node(FLIRT(output_type='NIFTI',\n",
    "                          reference=template),\n",
    "                         name='linearReg')\n",
    "\n",
    "quant_cbf_alsop = Node(name='quant_cbf_alsop',\n",
    "                interface=Function(input_names=['pw_volume','pd_volume',\n",
    "                                                'sat_time','postlabel_delay',\n",
    "                                                'T1_blood','labeling_time',\n",
    "                                                'efficiency','partition_coeff',\n",
    "                                                'TR','T1_tissue','scaling_factor',\n",
    "                                                'nex_asl'],\n",
    "                                  output_names=['cbf_volume'],\n",
    "                                  function=quantify_cbf_alsop))\n",
    "quant_cbf_alsop.inputs.sat_time=sat_time\n",
    "quant_cbf_alsop.inputs.postlabel_delay=postlabel_delay\n",
    "quant_cbf_alsop.inputs.T1_blood=T1_blood\n",
    "quant_cbf_alsop.inputs.labeling_time=labeling_time\n",
    "quant_cbf_alsop.inputs.efficiency=efficiency\n",
    "quant_cbf_alsop.inputs.partition_coeff=partition_coeff\n",
    "quant_cbf_alsop.inputs.TR=TR\n",
    "quant_cbf_alsop.inputs.T1_tissue=T1_tissue\n",
    "quant_cbf_alsop.inputs.scaling_factor=scaling_factor\n",
    "quant_cbf_alsop.inputs.nex_asl=nex_asl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a flow for preprocessing anat + asl volumes \n",
    "preprocflow = Workflow(name='preprocflow')\n",
    "\n",
    "# Connect all components of the preprocessing workflow\n",
    "preprocflow.connect([(infosource, selectfiles, [('subjid', 'subjid')]),\n",
    "                      (infosource, fssource, [('subjid','subject_id')]),\n",
    "                      (fssource, mri_convert, [('brainmask', 'in_file')]),\n",
    "                     ])\n",
    "preprocflow.base_dir = opj(wkflow_dir)\n",
    "preprocflow.write_graph(graph2use='flat')\n",
    "preprocflow.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bandpass_filter(in_file, lowpass, highpass, TR):\n",
    "    import numpy as np\n",
    "    import nibabel as nb\n",
    "    from os.path import abspath\n",
    "    from nipype.interfaces.afni.preprocess import Bandpass\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    out_file = 'func_filtered'\n",
    "    bp = Bandpass()\n",
    "    bp.inputs.highpass = highpass\n",
    "    bp.inputs.lowpass = lowpass\n",
    "    bp.inputs.in_file = in_file\n",
    "    bp.inputs.tr = TR\n",
    "    bp.inputs.out_file = out_file\n",
    "    bp.inputs.outputtype = 'NIFTI'\n",
    "    bp.run()\n",
    "    \n",
    "    out_file = abspath(out_file + '.nii')\n",
    "    return(out_file)\n",
    "\n",
    "def adjust_masks(masks):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from nipype.interfaces.freesurfer.model import Binarize\n",
    "    #pve0 = csf, pve1 = gm, pve2 = wm\n",
    "    \n",
    "    origvols = sorted(masks)\n",
    "    csf = origvols[0]\n",
    "    wm = origvols[2]\n",
    "    vols = []\n",
    "    \n",
    "    binary = Binarize()\n",
    "    binary.inputs.in_file = wm\n",
    "    binary.inputs.min = 0.5\n",
    "    binary.inputs.max = 2\n",
    "    binary.inputs.binary_file = 'WM_seg.nii'\n",
    "    binary.run()\n",
    "    wm_new = abspath(binary.inputs.binary_file)\n",
    "    vols.append(wm_new)\n",
    "    \n",
    "    binary2 = Binarize()\n",
    "    binary2.inputs.in_file = csf\n",
    "    binary2.erode = 1\n",
    "    binary2.inputs.min = 0.5\n",
    "    binary2.inputs.max = 2\n",
    "    binary2.inputs.binary_file = 'CSF_seg.nii'\n",
    "    binary2.run()\n",
    "    csf_new = abspath(binary2.inputs.binary_file)\n",
    "    vols.append(csf_new)\n",
    "    \n",
    "    return(vols)\n",
    "    \n",
    "def create_noise_matrix(vols_to_censor,motion_params,comp_noise):\n",
    "    from numpy import genfromtxt, zeros, column_stack, savetxt\n",
    "    from os import path\n",
    "    \n",
    "    motion = genfromtxt(motion_params, delimiter=None, dtype=None, skip_header=0)\n",
    "    comp_noise = genfromtxt(comp_noise, delimiter=None, dtype=None, skip_header=1)\n",
    "    censor_vol_list = genfromtxt(vols_to_censor, delimiter=None, dtype=None, skip_header=0)\n",
    "    \n",
    "    try:\n",
    "        c = censor_vol_list.size\n",
    "    except:\n",
    "        c = 0\n",
    "    \n",
    "    d=len(comp_noise)\n",
    "\n",
    "    if c > 1:\n",
    "        scrubbing = zeros((d,c),dtype=int)\n",
    "        for t in range(c):\n",
    "            scrubbing[censor_vol_list[t],t] = 1\n",
    "        noise_matrix = column_stack((motion,comp_noise,scrubbing))\n",
    "    elif c == 1:\n",
    "        scrubbing = zeros((d,c),dtype=int)\n",
    "        scrubbing[censor_vol_list] = 1\n",
    "        noise_matrix = column_stack((motion,comp_noise,scrubbing))\n",
    "    else:\n",
    "        noise_matrix = column_stack((motion,comp_noise))\n",
    "    \n",
    "    noise_file = 'noise_matrix.txt'\n",
    "    savetxt(noise_file, noise_matrix)\n",
    "    noise_filepath = path.abspath(noise_file)\n",
    "    \n",
    "    return(noise_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resting state preprocessing nodes\n",
    "\n",
    "# Realign each volume to first volume: in_file; out_file, par_file\n",
    "realign_merged = Node(MCFLIRT(out_file='rmerged.nii',\n",
    "                              ref_vol=0), \n",
    "                      name='realign_merged')\n",
    "\n",
    "# Slice time correction: in_file, slice_time_corrected_file\n",
    "slicetime = MapNode(SliceTimer(time_repetition=TR, \n",
    "                               interleaved=interleaved, \n",
    "                               slice_direction=slice_direction, \n",
    "                               out_file='stfunc.nii'), \n",
    "                    name='slicetime',\n",
    "                    iterfield=['in_file'])\n",
    "\n",
    "# register the functional volumes to the subject space anat\n",
    "# inputs: in_file, reference; out_file out_matrix_file\n",
    "reg_func_to_anat = MapNode(FLIRT(out_matrix_file='xform.mat'),\n",
    "                           name='reg_func_to_anat', \n",
    "                           iterfield=['in_file'])\n",
    "\n",
    "apply_reg_to_func = MapNode(FLIRT(apply_xfm=True, \n",
    "                               out_file='warped_func.nii'), \n",
    "                            name='apply_reg_to_func', \n",
    "                            iterfield=['in_file','in_matrix_file'])\n",
    "\n",
    "# Apply binary mask to merged functional scan: in_file, mask_file; out_file\n",
    "mask_func = Node(ApplyMask(out_file='masked_func.nii'), \n",
    "                 name='mask_func')\n",
    "\n",
    "# Bandpass Filtering (0.01-0.1 per Rissman et al 2004) all rates are in Hz (1/TR or samples/second)\n",
    "bandpass = Node(name='bandpass', \n",
    "                interface=Function(input_names=['in_file','lowpass','highpass','TR'], \n",
    "                                   output_names=['out_file'],\n",
    "                                   function=bandpass_filter))\n",
    "bandpass.inputs.lowpass = lowpass_freq\n",
    "bandpass.inputs.highpass = highpass_freq\n",
    "bandpass.inputs.TR = TR\n",
    "\n",
    "# Artifact detection for scrubbing/motion assessment\n",
    "art = Node(ArtifactDetect(mask_type='file',\n",
    "                          parameter_source='FSL',\n",
    "                          norm_threshold=1.0, #mutually exclusive with rotation and translation thresh\n",
    "                          zintensity_threshold=3,\n",
    "                          use_differences=[True, False]),\n",
    "           name='art')\n",
    "\n",
    "# Segment structural scan\n",
    "segment = Node(FAST(no_bias=True, \n",
    "                    segments=True, \n",
    "                    number_classes=3), \n",
    "               name='segment')\n",
    "\n",
    "# Fix the segmentations\n",
    "fix_confs = Node(name='fix_confs',\n",
    "                 interface=Function(input_names=['masks'], \n",
    "                                    output_names=['vols'],\n",
    "                                    function=adjust_masks))\n",
    "# actually run compcor\n",
    "compcor = Node(CompCor(merge_method='none'), \n",
    "               name='compcor')\n",
    "\n",
    "# Create a denoising mask with compcor + motion\n",
    "noise_mat = Node(name='noise_mat', interface=Function(input_names=['vols_to_censor','motion_params','comp_noise'],\n",
    "                                                      output_names=['noise_filepath'], \n",
    "                                                      function=create_noise_matrix))\n",
    "\n",
    "# Denoise the data\n",
    "denoise = Node(GLM(out_res_name='denoised_residuals.nii', \n",
    "                   out_data_name='denoised_func.nii'), \n",
    "               name='denoise')\n",
    "\n",
    "# Register to MNI space\n",
    "reg_rest2standard = Node(FLIRT(), \n",
    "                         name = 'reg_rest2standard')\n",
    "\n",
    "# Apply the transform to all volumes\n",
    "rest_applyXform = Node(FLIRT(), \n",
    "                       name = 'rest_applyXform')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_coreg_plot(epi,anat):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    from nipype.interfaces.nipy.preprocess import Trim\n",
    "    \n",
    "    epiVol = 'firstVol.nii'\n",
    "    trim = Trim()\n",
    "    trim.inputs.in_file = epi\n",
    "    trim.inputs.out_file = epiVol\n",
    "    trim.inputs.end_index = 1\n",
    "    trim.inputs.begin_index = 0\n",
    "    trim.run()\n",
    "    \n",
    "    coreg_filename='coregistration.png'\n",
    "    display = plotting.plot_anat(epiVol, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'coregistration to anatomy')\n",
    "    display.add_edges(anat)\n",
    "    display.savefig(coreg_filename) \n",
    "    display.close()\n",
    "    coreg_file = abspath(coreg_filename)\n",
    "    \n",
    "    return(coreg_file)\n",
    "\n",
    "def check_mask_coverage(epi,brainmask):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    from PIL import Image\n",
    "    from numpy import sum, asarray, vstack\n",
    "    from nipype.interfaces.nipy.preprocess import Trim\n",
    "    \n",
    "    epiVol = 'firstVol.nii'\n",
    "    trim = Trim()\n",
    "    trim.inputs.in_file = epi\n",
    "    trim.inputs.out_file = epiVol\n",
    "    trim.inputs.end_index = 1\n",
    "    trim.inputs.begin_index = 0\n",
    "    trim.run()\n",
    "    \n",
    "    maskcheck_filename='maskcheck.png'\n",
    "    display = plotting.plot_anat(epiVol, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'check brainmask coverage')\n",
    "    display.add_contours(brainmask,levels=[.5], colors='r')\n",
    "    display.savefig(maskcheck_filename) \n",
    "    display.close()\n",
    "    \n",
    "    make_coreg_img = Node(Function(input_names=['epi','anat'],\n",
    "                                         output_names=['coreg_file'],\n",
    "                                         function=create_coreg_plot),\n",
    "                      name='make_coreg_img')\n",
    "\n",
    "make_checkmask_img = Node(Function(input_names=['epi','brainmask'],\n",
    "                                         output_names=['maskcheck_file'],\n",
    "                                         function=check_mask_coverage),\n",
    "                          name='make_checkmask_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# workflow\n",
    "preprocflow = Workflow(name='preprocflow')\n",
    "preprocflow.connect([(infosource,structgrabber,[('subjid','subjid')]),\n",
    "                     (infosource,structgrabber,[('timepoint','timepoint')]),\n",
    "                     (structgrabber,fs_preproc,[('struct','T1_files')]),\n",
    "                     (infosource,get_fsID,[('subjid','subjid')]),\n",
    "                     (infosource,get_fsID,[('timepoint','timepoint')]),\n",
    "                     (get_fsID,fs_preproc,[('fs_subjid','subject_id')]),\n",
    "                     (fs_preproc, convert_anat,[('brainmask','in_file')]),\n",
    "                     (convert_anat,reorient_anat,[('out_file','in_file')]),\n",
    "                     (reorient_anat,segment,[('out_file','in_files')]),\n",
    "                     (segment,fix_confs,[('tissue_class_files','masks')]),\n",
    "                     (fix_confs,compcor,[('vols','mask_files')]),\n",
    "                     (reorient_anat, binarize_anat,[('out_file','in_file')]),\n",
    "                     (reorient_anat,reg_func_to_anat,[('out_file','reference')]),\n",
    "                     (reorient_anat,apply_reg_to_func,[('out_file','reference')]),\n",
    "                     (binarize_anat,mask_func,[('binary_file','mask_file')]),\n",
    "                     (binarize_anat,art,[('binary_file','mask_file')]),\n",
    "                     \n",
    "                     (infosource,funcgrabber,[('subjid','subjid')]),\n",
    "                     (infosource,funcgrabber,[('timepoint','timepoint')]),\n",
    "                     (funcgrabber,unzip_func,[('func','in_file')]),\n",
    "                     (unzip_func,reorient_func,[('out_file','in_file')]),\n",
    "                     (reorient_func,realign_runs,[('out_file','in_file')]),\n",
    "                     (realign_runs, slicetime,[('out_file','in_file')]),\n",
    "                     (slicetime,reg_func_to_anat,[('slice_time_corrected_file','in_file')]),\n",
    "                     (slicetime,apply_reg_to_func,[('slice_time_corrected_file','in_file')]),\n",
    "                     (reg_func_to_anat,apply_reg_to_func,[('out_matrix_file','in_matrix_file')]),\n",
    "                     (apply_reg_to_func,norm_run_intensities,[('out_file','func_files')]),\n",
    "                     (norm_run_intensities,merge_func,[('new_func_list','in_files')]),\n",
    "                     (merge_func,realign_merged,[('merged_file','in_file')]),\n",
    "                     (realign_merged,mask_func,[('out_file','in_file')]),\n",
    "                     \n",
    "                     (realign_runs,merge_motion,[('par_file','motion_files')]),\n",
    "                     (mask_func,merge_motion,[('out_file','merged_func')]),\n",
    "                     (mask_func,art,[('out_file','realigned_files')]),\n",
    "                     (merge_motion,art,[('newmotion_params','realignment_parameters')]),\n",
    "                     (mask_func,compcor,[('out_file','realigned_file')]),\n",
    "                     (compcor,noise_mat,[('components_file','comp_noise')]),\n",
    "                     (art,noise_mat,[('outlier_files','vols_to_censor')]),\n",
    "                     (merge_motion,noise_mat,[('newmotion_params','motion_params')]),\n",
    "                     (noise_mat,denoise,[('noise_filepath','design')]),\n",
    "                     (mask_func,denoise,[('out_file','in_file')]),\n",
    "                     (denoise,bandpass,[('out_data','in_file')]),\n",
    "                     \n",
    "                     (realign_merged,make_coreg_img,[('out_file','epi')]),\n",
    "                     (reorient_anat,make_coreg_img,[('out_file','anat')]),\n",
    "                     (realign_merged,make_checkmask_img,[('out_file','epi')]),\n",
    "                     (binarize_anat,make_checkmask_img,[('binary_file','brainmask')]),\n",
    "                     \n",
    "                     (merge_func,datasink,[('merged_file','merged_func')]),\n",
    "                     (make_coreg_img,datasink,[('coreg_file','coregcheck_image')]),\n",
    "                     (make_checkmask_img,datasink,[('maskcheck_file','maskcheck_image')]),\n",
    "                     (mask_func, datasink,[('out_file','orig_merged_func')]),\n",
    "                     (reorient_anat,datasink,[('out_file','preproc_anat')]),\n",
    "                     (binarize_anat,datasink,[('binary_file','binarized_anat')]),\n",
    "                     (merge_motion, datasink,[('newmotion_params','motion_params')]),\n",
    "                     (noise_mat,datasink,[('noise_filepath','full_noise_mat')]),\n",
    "                     (art,datasink,[('plot_files','art_plot_files')]),\n",
    "                     (bandpass,datasink,[('out_file','preproc_func')])        \n",
    "                    ])\n",
    "preprocflow.base_dir = workflow_dir\n",
    "preprocflow.write_graph(graph2use='flat')\n",
    "preprocflow.run('MultiProc', plugin_args={'n_procs': 10})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
