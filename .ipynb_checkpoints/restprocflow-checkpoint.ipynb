{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.utility import Function, IdentityInterface\n",
    "from nipype.interfaces.io import FreeSurferSource, SelectFiles, DataSink\n",
    "from nipype.pipeline.engine import Workflow, Node\n",
    "\n",
    "from nipype.interfaces.freesurfer import Binarize, MRIConvert, FSCommand\n",
    "from nipype.interfaces.fsl import ApplyMask, Reorient2Std, MotionOutliers\n",
    "from nipype.interfaces.fsl.preprocess import MCFLIRT, SliceTimer, FLIRT, FAST, SUSAN\n",
    "from nipype.interfaces.fsl.model import GLM\n",
    "from nipype.algorithms.confounds import CompCor\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "from nipype.interfaces.nipy.preprocess import Trim\n",
    "\n",
    "#other study-specific variables\n",
    "project_home = '/Users/catcamacho/Dropbox/projects/th_nar_asl/proc'\n",
    "raw_dir = project_home + '/raw'\n",
    "output_dir = project_home + '/proc/rest_preproc'\n",
    "workflow_dir = project_home + '/workflows'\n",
    "asl_dir = project_home + '/proc/asl_preproc'\n",
    "\n",
    "subjects_list = open(project_home + '/misc/subjects.txt').read().splitlines()\n",
    "#subjects_list = ['003-DT2']\n",
    "\n",
    "#freesurfer setup\n",
    "subjects_dir = project_home + '/freesurfer'\n",
    "FSCommand.set_default_subjects_dir(subjects_dir)\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "# Study variables for resting state processing\n",
    "rest_TR = 2 #in seconds\n",
    "num_slices = 29\n",
    "slice_direction = 3 #3 = z direction\n",
    "interleaved = True\n",
    "#all rates are in Hz (1/TR or samples/second)\n",
    "highpass_freq = 0.008 #in Hz\n",
    "lowpass_freq = 0.09 #in Hz\n",
    "vols_to_trim = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select subjects\n",
    "infosource = Node(IdentityInterface(fields=['subjid']),\n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subjects_list)]\n",
    "\n",
    "# SelectFiles\n",
    "templates = {'rest': raw_dir + '/{subjid}/rest_raw.nii.gz', \n",
    "             'proc_anat':asl_dir + '/preproc_anat/{subjid}/brainmask_out_reoriented.nii',\n",
    "             'mask':asl_dir + '/brainmask/{subjid}/brainmask_out_reoriented_thresh.nii'}\n",
    "selectfiles = Node(SelectFiles(templates), name='selectfiles')\n",
    "\n",
    "# FreeSurferSource - Data grabber specific for FreeSurfer data\n",
    "fssource = Node(FreeSurferSource(subjects_dir=subjects_dir),\n",
    "                run_without_submitting=True,\n",
    "                name='fssource')\n",
    "# Datasink\n",
    "datasink = Node(DataSink(base_directory = output_dir, \n",
    "                         container = output_dir), \n",
    "                name='datasink')\n",
    "\n",
    "# DataSink output substitutions (for ease of folder naming)\n",
    "substitutions = [('_subjid_', '')]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nb\n",
    "from os.path import abspath, exists\n",
    "from nipype.interfaces.afni.preprocess import Bandpass\n",
    "from nipype.interfaces.afni.utils import AFNItoNIFTI\n",
    "\n",
    "#in_file = '/Users/catcamacho/Dropbox/Projects/th_nar_asl/proc/workflows/restpreproc/_subjid_003-DT2/denoise/denoised_func.nii.gz'\n",
    "#lowpass = 0.09 \n",
    "#highpass = 0.008\n",
    "#TR = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(in_file, lowpass, highpass, TR):\n",
    "    import numpy as np\n",
    "    import nibabel as nb\n",
    "    from os.path import abspath, exists\n",
    "    from nipype.interfaces.afni.preprocess import Bandpass\n",
    "    from nipype.interfaces.afni.utils import AFNItoNIFTI\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    out_file = 'func_filtered'\n",
    "    bp = Bandpass()\n",
    "    bp.inputs.highpass = highpass\n",
    "    bp.inputs.lowpass = lowpass\n",
    "    bp.inputs.in_file = in_file\n",
    "    bp.inputs.tr = TR\n",
    "    bp.inputs.out_file = out_file\n",
    "    bp.inputs.outputtype = 'NIFTI_GZ'\n",
    "    bp.run()\n",
    "\n",
    "    if not exists(out_file + '.nii.gz'):\n",
    "        cvt = AFNItoNIFTI()\n",
    "        cvt.inputs.in_file = 'func_filtered+orig.BRIK'\n",
    "        cvt.inputs.outputtype = 'NIFTI_GZ'\n",
    "        cvt.inputs.out_file = out_file + 'cvt.nii.gz'\n",
    "        out_file = abspath(out_file + 'cvt.nii.gz')\n",
    "    else:\n",
    "        out_file = abspath(out_file + '.nii.gz')\n",
    "    \n",
    "    return(out_file)\n",
    "\n",
    "def adjust_masks(masks):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from nipype.interfaces.freesurfer.model import Binarize\n",
    "    #pve0 = csf, pve1 = gm, pve2 = wm\n",
    "    \n",
    "    origvols = sorted(masks)\n",
    "    csf = origvols[0]\n",
    "    wm = origvols[2]\n",
    "    vols = []\n",
    "    \n",
    "    wm_file = 'WM_seg.nii.gz'\n",
    "    binary = Binarize()\n",
    "    binary.inputs.in_file = wm\n",
    "    binary.inputs.min = 0.5\n",
    "    binary.inputs.max = 2\n",
    "    binary.inputs.binary_file = wm_file\n",
    "    binary.run()\n",
    "    wm_new = abspath(wm_file)\n",
    "    vols.append(wm_new)\n",
    "    \n",
    "    csf_file = 'CSF_seg.nii.gz'\n",
    "    binary2 = Binarize()\n",
    "    binary2.inputs.in_file = csf\n",
    "    binary2.erode = 1\n",
    "    binary2.inputs.min = 0.5\n",
    "    binary2.inputs.max = 2\n",
    "    binary2.inputs.binary_file = csf_file\n",
    "    binary2.run()\n",
    "    csf_new = abspath(csf_file)\n",
    "    vols.append(csf_new)\n",
    "    \n",
    "    return(vols)\n",
    "\n",
    "## This reads in the output from fsl_motion_outliers as opposed to ART\n",
    "def create_noise_matrix(vols_to_censor,motion_params,comp_noise):\n",
    "    from numpy import genfromtxt, zeros, column_stack, savetxt\n",
    "    from os import path\n",
    "    \n",
    "    motion = genfromtxt(motion_params, delimiter=None, dtype=None, skip_header=0)\n",
    "    comp_noise = genfromtxt(comp_noise, delimiter=None, dtype=None, skip_header=1)\n",
    "    censor_vol_list = genfromtxt(vols_to_censor, delimiter=None, dtype=None, skip_header=0)\n",
    "    \n",
    "    (a,b) = censor_vol_list.shape\n",
    "    if b > 0:\n",
    "        scrubbing = censor_vol_list\n",
    "        noise_matrix = column_stack((motion,comp_noise,scrubbing))\n",
    "    else:\n",
    "        try:\n",
    "            c = censor_vol_list.size\n",
    "        except:\n",
    "            c = 0\n",
    "        d=len(comp_noise)\n",
    "\n",
    "        if c > 1:\n",
    "            scrubbing = zeros((d,c),dtype=int)\n",
    "            for t in range(c):\n",
    "                scrubbing[censor_vol_list[t],t] = 1\n",
    "            noise_matrix = column_stack((motion,comp_noise,scrubbing))\n",
    "        elif c == 1:\n",
    "            scrubbing = zeros((d,c),dtype=int)\n",
    "            scrubbing[censor_vol_list] = 1\n",
    "            noise_matrix = column_stack((motion,comp_noise,scrubbing))\n",
    "        else:\n",
    "            noise_matrix = column_stack((motion,comp_noise))\n",
    "    \n",
    "    noise_file = 'noise_matrix.txt'\n",
    "    savetxt(noise_file, noise_matrix)\n",
    "    noise_filepath = path.abspath(noise_file)\n",
    "    \n",
    "    return(noise_filepath)\n",
    "\n",
    "\n",
    "# Smooth the data\n",
    "def brightthresh(func):\n",
    "    import nibabel as nib\n",
    "    from numpy import median, where\n",
    "    \n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    func_nifti1 = nib.load(func)\n",
    "    func_data = func_nifti1.get_data()\n",
    "    func_data = func_data.astype(float)\n",
    "    \n",
    "    brain_values = where(func_data > 0)\n",
    "    median_thresh = median(brain_values)\n",
    "    bright_thresh = 0.75 * median_thresh\n",
    "    \n",
    "    return(bright_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coreg_plot(epi,anat):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    from nipype.interfaces.nipy.preprocess import Trim\n",
    "    \n",
    "    epiVol = 'firstVol.nii.gz'\n",
    "    trim = Trim()\n",
    "    trim.inputs.in_file = epi\n",
    "    trim.inputs.out_file = epiVol\n",
    "    trim.inputs.end_index = 1\n",
    "    trim.inputs.begin_index = 0\n",
    "    trim.run()\n",
    "    \n",
    "    coreg_filename='coregistration.png'\n",
    "    display = plotting.plot_anat(epiVol, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'coregistration to anatomy')\n",
    "    display.add_edges(anat)\n",
    "    display.savefig(coreg_filename) \n",
    "    display.close()\n",
    "    coreg_file = abspath(coreg_filename)\n",
    "    \n",
    "    return(coreg_file)\n",
    "\n",
    "def check_mask_coverage(epi,brainmask):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    from nipype.interfaces.nipy.preprocess import Trim\n",
    "    \n",
    "    epiVol = 'firstVol.nii.gz'\n",
    "    trim = Trim()\n",
    "    trim.inputs.in_file = epi\n",
    "    trim.inputs.out_file = epiVol\n",
    "    trim.inputs.end_index = 1\n",
    "    trim.inputs.begin_index = 0\n",
    "    trim.run()\n",
    "    \n",
    "    maskcheck_filename='maskcheck.png'\n",
    "    display = plotting.plot_anat(epiVol, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'check brainmask coverage')\n",
    "    display.add_contours(brainmask,levels=[.5], colors='r')\n",
    "    display.savefig(maskcheck_filename) \n",
    "    display.close()\n",
    "    checkmask_file = abspath(maskcheck_filename)\n",
    "    \n",
    "    return(checkmask_file)\n",
    "    \n",
    "make_coreg_img = Node(Function(input_names=['epi','anat'],\n",
    "                                         output_names=['coreg_file'],\n",
    "                                         function=create_coreg_plot),\n",
    "                      name='make_coreg_img')\n",
    "\n",
    "make_checkmask_img = Node(Function(input_names=['epi','brainmask'],\n",
    "                                         output_names=['maskcheck_file'],\n",
    "                                         function=check_mask_coverage),\n",
    "                          name='make_checkmask_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resting state preprocessing nodes\n",
    "\n",
    "# Trim the initial volumes\n",
    "trim = Node(Trim(begin_index=vols_to_trim), name='trim')\n",
    "\n",
    "# reorient the functional data\n",
    "reorient_func = Node(Reorient2Std(), name='reorient_func')\n",
    "\n",
    "# Realign each volume to first volume: in_file; out_file, par_file\n",
    "realign = Node(MCFLIRT(out_file='realigned_func.nii.gz',\n",
    "                       save_plots=True, \n",
    "                       mean_vol=True\n",
    "                      ), \n",
    "               name='realign')\n",
    "\n",
    "# Slice time correction: in_file, slice_time_corrected_file\n",
    "slicetime = Node(SliceTimer(time_repetition=rest_TR, \n",
    "                            interleaved=interleaved,\n",
    "                            slice_direction=slice_direction, \n",
    "                            out_file='stfunc.nii.gz'), \n",
    "                    name='slicetime')\n",
    "\n",
    "# register the functional volumes to the subject space anat\n",
    "# inputs: in_file, reference; out_file out_matrix_file\n",
    "reg_func_to_anat = Node(FLIRT(out_matrix_file='xform.mat'),\n",
    "                        name='reg_func_to_anat')\n",
    "\n",
    "apply_reg_to_func = Node(FLIRT(apply_xfm=True, \n",
    "                               out_file='warped_func.nii.gz'),  \n",
    "                         name='apply_reg_to_func')\n",
    "\n",
    "# Apply binary mask to merged functional scan: in_file, mask_file; out_file\n",
    "mask_func = Node(ApplyMask(out_file='masked_func.nii.gz'), \n",
    "                 name='mask_func')\n",
    "\n",
    "# Bandpass Filtering all rates are in Hz (1/TR or samples/second)\n",
    "#bandpass = Node(name='bandpass', \n",
    "#                interface=Function(input_names=['in_file','lowpass','highpass','TR'], \n",
    "#                                   output_names=['out_file'],\n",
    "#                                   function=bandpass_filter))\n",
    "#bandpass.inputs.lowpass = lowpass_freq\n",
    "#bandpass.inputs.highpass = highpass_freq\n",
    "#bandpass.inputs.TR = rest_TR\n",
    "\n",
    "bandpass = Node(TemporalFilter(), name='bandpass')\n",
    "\n",
    "# gunzip the fmri file before putiing it through ART\n",
    "unzip = Node(Gunzip(), name='unzip')\n",
    "\n",
    "get_FD = Node(MotionOutliers(threshold=0.25, \n",
    "                             metric='fd', \n",
    "                             no_motion_correction=False, \n",
    "                             out_file='outliers.txt', \n",
    "                             out_metric_plot='fd.png', \n",
    "                             out_metric_values='fd.txt'), \n",
    "              name='get_FD')\n",
    "\n",
    "# Segment structural scan\n",
    "segment = Node(FAST(no_bias=True, \n",
    "                    segments=True, \n",
    "                    number_classes=3), \n",
    "               name='segment')\n",
    "\n",
    "# Fix the segmentations\n",
    "fix_confs = Node(name='fix_confs',\n",
    "                 interface=Function(input_names=['masks'], \n",
    "                                    output_names=['vols'],\n",
    "                                    function=adjust_masks))\n",
    "# actually run compcor\n",
    "compcor = Node(CompCor(merge_method='none', \n",
    "                       num_components=3), \n",
    "               name='compcor')\n",
    "\n",
    "# Create a denoising mask with compcor + motion\n",
    "noise_mat = Node(name='noise_mat', interface=Function(input_names=['vols_to_censor','motion_params','comp_noise'],\n",
    "                                                      output_names=['noise_filepath'], \n",
    "                                                      function=create_noise_matrix))\n",
    "\n",
    "# Denoise the data\n",
    "denoise = Node(GLM(out_res_name='denoised_residuals.nii.gz', \n",
    "                   out_data_name='denoised_func.nii.gz'), \n",
    "               name='denoise')\n",
    "\n",
    "# Register to MNI space\n",
    "reg_rest2standard = Node(FLIRT(reference=template), \n",
    "                         name = 'reg_rest2standard')\n",
    "\n",
    "# Apply the transform to all volumes\n",
    "rest_applyXform = Node(FLIRT(reference=template,apply_xfm=True), \n",
    "                       name = 'rest_applyXform')\n",
    "\n",
    "# Smooth the data\n",
    "brightthresh = Node(Function(input_names=['func'],\n",
    "                             output_names=['bright_thresh'],\n",
    "                             function=brightthresh),\n",
    "                    name='brightthresh')\n",
    "smooth = Node(SUSAN(fwhm=smoothing_kernel),\n",
    "              name='smooth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "from os.path import isdir\n",
    "from pandas import DataFrame\n",
    "\n",
    "motion_df = DataFrame(columns=['meanFD','maxFD','NumCensoredVols'])\n",
    "\n",
    "if isdir(output_dir + '/motion_summary') ==False:\n",
    "    makedirs(output_dir + '/motion_summary')\n",
    "    \n",
    "motion_df_file = output_dir + '/motion_summary/motionSummary.csv'\n",
    "motion_df.to_csv(motion_df_file)\n",
    "\n",
    "def summarize_motion(motion_df_file, motion_file, vols_to_censor, subject):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from os.path import dirname, basename\n",
    "    from numpy import asarray, mean, sum, genfromtxt\n",
    "    from pandas import DataFrame, Series, read_csv\n",
    "    \n",
    "    motion_df = read_csv(motion_df_file, index_col=0)\n",
    "    \n",
    "    motion = asarray(open(motion_file).read().splitlines()).astype(float)\n",
    "    censor_vols = genfromtxt(vols_to_censor, delimiter=None, dtype=None, skip_header=0)\n",
    "\n",
    "    motion_df.loc[subject] = [mean(motion),max(motion),sum(censor_vols)]\n",
    "    motion_df.to_csv(motion_df_file)\n",
    "\n",
    "    return()\n",
    "\n",
    "motion_summary = Node(Function(input_names=['motion_df_file','motion_file','vols_to_censor','subject'], \n",
    "                               output_names=[], \n",
    "                               function=summarize_motion), \n",
    "                      name='motion_summary')\n",
    "motion_summary.inputs.motion_df_file = motion_df_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# workflow\n",
    "## need to add in FD rather than ART\n",
    "\n",
    "restpreproc = Workflow(name='restpreproc')\n",
    "restpreproc.connect([(infosource,selectfiles,[('subjid','subjid')]),\n",
    "                     (infosource,motion_summary,[('subjid','subject')]),\n",
    "                     (selectfiles,reg_func_to_anat,[('proc_anat','reference')]),\n",
    "                     (selectfiles,apply_reg_to_func,[('proc_anat','reference')]),\n",
    "                     (selectfiles,mask_func,[('mask','mask_file')]),\n",
    "                     (selectfiles,segment, [('proc_anat','in_files')]),\n",
    "                     \n",
    "                     (selectfiles,reorient_func,[('rest','in_file')]),\n",
    "                     (reorient_func,trim,[('out_file','in_file')]),\n",
    "                     (trim,realign,[('out_file','in_file')]),\n",
    "                     (realign,slicetime,[('out_file','in_file')]),\n",
    "                     (slicetime,reg_func_to_anat,[('slice_time_corrected_file','in_file')]),\n",
    "                     (slicetime,apply_reg_to_func,[('slice_time_corrected_file','in_file')]),\n",
    "                     (reg_func_to_anat,apply_reg_to_func,[('out_matrix_file','in_matrix_file')]),\n",
    "                     (apply_reg_to_func,mask_func,[('out_file','in_file')]),\n",
    "                     \n",
    "                     (segment,fix_confs,[('tissue_class_files','masks')]),\n",
    "                     (fix_confs,compcor,[('vols','mask_files')]),\n",
    "                     (trim,get_FD, [('out_file','in_file')]),\n",
    "                     (get_FD,noise_mat,[('out_file','vols_to_censor')]),\n",
    "                     (get_FD,noise_mat,[('out_metric_values','motion_params')]),\n",
    "                     (mask_func,compcor,[('out_file','realigned_file')]),\n",
    "                     (compcor,noise_mat,[('components_file','comp_noise')]),\n",
    "                     (noise_mat,denoise,[('noise_filepath','design')]),\n",
    "                     (mask_func,denoise,[('out_file','in_file')]),\n",
    "                     (denoise,bandpass,[('out_data','in_file')]),\n",
    "                     \n",
    "                     (get_FD, motion_summary, [('out_metric_values','motion_file'),\n",
    "                                               ('out_file','vols_to_censor')]),\n",
    "                     \n",
    "                     (mask_func,make_coreg_img,[('out_file','epi')]),\n",
    "                     (selectfiles,make_coreg_img,[('proc_anat','anat')]),\n",
    "                     \n",
    "                     (bandpass,brightthresh,[('out_file','func')]),\n",
    "                     (bandpass,smooth,[('out_file','in_file')]),\n",
    "                     (brightthresh,smooth,[('bright_thresh','brightness_threshold')]),\n",
    "                     (selectfiles,reg_rest2standard,[('proc_anat','in_file')]),\n",
    "                     (reg_rest2standard,rest_applyXform,[('out_matrix_file','in_matrix_file')]),\n",
    "                     (smooth,rest_applyXform,[('smoothed_file','in_file')]),\n",
    "                     \n",
    "                     (rest_applyXform, datasink,[('out_file','preproc_func')]),\n",
    "                     (make_coreg_img,datasink,[('coreg_file','coregcheck_image')]),\n",
    "                     (get_FD, datasink, [('out_metric_plot','FD_plot')])      \n",
    "                    ])\n",
    "restpreproc.base_dir = workflow_dir\n",
    "restpreproc.write_graph(graph2use='flat')\n",
    "restpreproc.run('MultiProc', plugin_args={'n_procs': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
