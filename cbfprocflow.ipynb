{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.utility import Function, IdentityInterface\n",
    "from nipype.interfaces.io import FreeSurferSource, SelectFiles, DataSink\n",
    "from nipype.pipeline.engine import Workflow, Node\n",
    "\n",
    "from nipype.interfaces.freesurfer import Binarize, MRIConvert, FSCommand\n",
    "from nipype.interfaces.fsl import ApplyMask, Reorient2Std\n",
    "from nipype.interfaces.fsl.preprocess import MCFLIRT, SliceTimer, FLIRT, FAST\n",
    "from nipype.interfaces.spm.preprocess import Smooth\n",
    "from nipype.algorithms.rapidart import ArtifactDetect\n",
    "from nipype.interfaces.fsl.model import GLM\n",
    "from nipype.algorithms.confounds import CompCor\n",
    "from nipype.interfaces.nipy.preprocess import Trim\n",
    "\n",
    "# MATLAB setup - Specify path to current SPM and the MATLAB's default mode\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('~/spm12/toolbox')\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "\n",
    "#other study-specific variables\n",
    "project_home = '/Users/catcamacho/Dropbox/Projects/TH_NAR_ASL/proc'\n",
    "raw_dir = project_home + '/raw'\n",
    "subjects_list = open(project_home + '/misc/subjects.txt').read().splitlines()\n",
    "output_dir = project_home + '/proc/preprocessing'\n",
    "wkflow_dir = project_home + '/workflows'\n",
    "template = project_home + '/template/MNI152_T1_2mm_brain.nii'\n",
    "\n",
    "#freesurfer setup\n",
    "subjects_dir = project_home + '/freesurfer'\n",
    "FSCommand.set_default_subjects_dir(subjects_dir)\n",
    "\n",
    "#Population specific variables for ASL\n",
    "nex_asl = 3 #number of excitations from the 3D ASL scan parameters\n",
    "inversion_efficiency = 0.8 #from GE\n",
    "background_supp_eff = 0.75 #from GE\n",
    "efficiency = inversion_efficiency * background_supp_eff \n",
    "T1_blood = 1.6 #T1 of blood in seconds(1.6s at 3T and 1.4s at 1.5T)\n",
    "sat_time = 2 #in seconds, from GE\n",
    "partition_coeff = 0.9 #whole brain average in ml/g\n",
    "scaling_factor = 32 #scaling factor, can be taken from PW dicom header at position 0043,107f (corresponds to #coils?)\n",
    "postlabel_delay = 1.525 #post label delay in seconds\n",
    "labeling_time = 1.450 #labeling time in seconds\n",
    "T1_tissue = 1.2 #estimated T1 of grey matter in seconds\n",
    "TR = 4.844 #repetition time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File handling nodes\n",
    "\n",
    "# Select subjects\n",
    "infosource = Node(IdentityInterface(fields=['subjid']),\n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subjects_list)]\n",
    "\n",
    "# SelectFiles\n",
    "templates = {'pw_volume': raw_dir + '/{subjid}/pw.nii',\n",
    "             'rest': raw_dir + '/{subjid}/rest_raw.nii',\n",
    "             'pd_volume': raw_dir + '/{subjid}/pd.nii'}\n",
    "selectfiles = Node(SelectFiles(templates), name='selectfiles')\n",
    "\n",
    "# FreeSurferSource - Data grabber specific for FreeSurfer data\n",
    "fssource = Node(FreeSurferSource(subjects_dir=subjects_dir),\n",
    "                run_without_submitting=True,\n",
    "                name='fssource')\n",
    "# Datasink\n",
    "datasink = Node(DataSink(base_directory = output_dir, \n",
    "                         container = output_dir), \n",
    "                name='datasink')\n",
    "\n",
    "# DataSink output substitutions (for ease of folder naming)\n",
    "substitutions = [('_subjid_', '')]\n",
    "datasink.inputs.substitutions = substitutions\n",
    "\n",
    "# Grab processed anat\n",
    "struct_template = {'proc_anat':output_dir + '/preproc_anat/{subjid}/brainmask_out_reoriented.nii'}\n",
    "structgrabber = Node(SelectFiles(struct_template),name='structgrabber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File Processing nodes\n",
    "\n",
    "# convert files to nifti\n",
    "mri_convert = Node(MRIConvert(out_type='nii',\n",
    "                              conform_size=2,\n",
    "                              crop_size= (128, 128, 128)), \n",
    "                   name='mri_convert')\n",
    "\n",
    "# reorient data for consistency\n",
    "reorient_anat = Node(Reorient2Std(output_type='NIFTI'),\n",
    "                     name='reorient_anat')\n",
    "\n",
    "# Binarize -  binarize and dilate image to create a brainmask\n",
    "binarize = Node(Binarize(min=0.5,\n",
    "                         max=300,\n",
    "                         dilate=3,\n",
    "                         erode=2,\n",
    "                         out_type='nii'),\n",
    "                name='binarize')\n",
    "\n",
    "# reorient PD/PW data for consistency\n",
    "reorient_pd = Node(Reorient2Std(output_type='NIFTI'),\n",
    "                   name='reorient_pd')\n",
    "\n",
    "reorient_pw = Node(Reorient2Std(output_type='NIFTI'),\n",
    "                   name='reorient_pw')\n",
    "\n",
    "# Register subject's PD/PW to subject anatomy\n",
    "reg_pw2anat = Node(FLIRT(output_type='NIFTI',\n",
    "                         out_file='warped_pw.nii'),\n",
    "                   name='reg_pw2anat')\n",
    "\n",
    "reg_pd2anat = Node(FLIRT(output_type='NIFTI',\n",
    "                         apply_xfm = True, \n",
    "                         out_file='warped_pd.nii'),\n",
    "                   name='reg_pd2anat')\n",
    "\n",
    "# Mask brain in pw volume\n",
    "applyMask_pw = Node(ApplyMask(output_type='NIFTI'),\n",
    "                    name='applyMask_pw')\n",
    "\n",
    "# Mask brain pd volumes\n",
    "applyMask_pd = Node(ApplyMask(output_type='NIFTI'), \n",
    "                    name='applyMask_pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom functions\n",
    "#quantify CBF from PW volume (Alsop MRIM 2015 method)\n",
    "def quantify_cbf_alsop(pw_volume,pd_volume,sat_time,postlabel_delay,T1_blood,labeling_time,efficiency,partition_coeff,TR,T1_tissue,scaling_factor,nex_asl):\n",
    "    import os\n",
    "    import nibabel as nib\n",
    "    from numpy import exp\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    # set variables\n",
    "    pw_nifti1 = nib.load(pw_volume)\n",
    "    pw_data = pw_nifti1.get_data()\n",
    "    pw_data = pw_data.astype(float)\n",
    "    pd_nifti1 = nib.load(pd_volume)\n",
    "    pd_data = pd_nifti1.get_data()\n",
    "    pd_data = pd_data.astype(float)\n",
    "    conversion = 6000 #to convert values from mL/g/s to mL/100g/min\n",
    "    pd_factor = 1/(1-exp((-1*TR)/T1_tissue))\n",
    "    \n",
    "    cbf_numerator = conversion*partition_coeff*pw_data*exp(postlabel_delay/T1_blood)\n",
    "    cbf_denominator = sat_time*efficiency*T1_blood*scaling_factor*nex_asl*pd_data*pd_factor*(1-exp((-1*labeling_time)/T1_blood))\n",
    "    cbf_data = cbf_numerator/cbf_denominator\n",
    "    \n",
    "    cbf_volume = nib.Nifti1Image(cbf_data, pw_nifti1.affine)\n",
    "    nib.save(cbf_volume, 'alsop_cbf.nii')\n",
    "    cbf_path = os.path.abspath('alsop_cbf.nii')\n",
    "    return cbf_path\n",
    "    \n",
    "def make_histogram(cbf_vol):\n",
    "    from os.path import abspath\n",
    "    from nibabel import load\n",
    "    from numpy import isnan\n",
    "    from matplotlib import pyplot as plt\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    cbf_image = load(cbf_vol)\n",
    "    cbf_data = cbf_image.get_data()\n",
    "\n",
    "    plt.Figure()\n",
    "    data = cbf_data.flatten()\n",
    "    plt.hist(data[~isnan(data)], bins = range(0,200,10))\n",
    "    plt.title(\"Distribution of CBF values in mL/100g/min\")\n",
    "    plt.savefig('cbf_histogram.png')\n",
    "    cbf_hist = abspath('cbf_histogram.png')\n",
    "    return(cbf_hist)\n",
    "\n",
    "def create_cbfcoreg_plot(ref,anat):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    \n",
    "    coreg_filename='coregistration.png'\n",
    "    display = plotting.plot_anat(ref, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'coregistration to anatomy')\n",
    "    display.add_edges(anat)\n",
    "    display.savefig(coreg_filename) \n",
    "    display.close()\n",
    "    coreg_file = abspath(coreg_filename)\n",
    "    \n",
    "    return(coreg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing data for first and second level analysis\n",
    "\n",
    "quant_cbf_alsop = Node(Function(input_names=['pw_volume','pd_volume',\n",
    "                                             'sat_time','postlabel_delay',\n",
    "                                             'T1_blood','labeling_time',\n",
    "                                             'efficiency','partition_coeff',\n",
    "                                             'TR','T1_tissue','scaling_factor',\n",
    "                                             'nex_asl'],\n",
    "                                output_names=['cbf_volume'],\n",
    "                                function=quantify_cbf_alsop),\n",
    "                       name='quant_cbf_alsop')\n",
    "quant_cbf_alsop.inputs.sat_time=sat_time\n",
    "quant_cbf_alsop.inputs.postlabel_delay=postlabel_delay\n",
    "quant_cbf_alsop.inputs.T1_blood=T1_blood\n",
    "quant_cbf_alsop.inputs.labeling_time=labeling_time\n",
    "quant_cbf_alsop.inputs.efficiency=efficiency\n",
    "quant_cbf_alsop.inputs.partition_coeff=partition_coeff\n",
    "quant_cbf_alsop.inputs.TR=TR\n",
    "quant_cbf_alsop.inputs.T1_tissue=T1_tissue\n",
    "quant_cbf_alsop.inputs.scaling_factor=scaling_factor\n",
    "quant_cbf_alsop.inputs.nex_asl=nex_asl\n",
    "\n",
    "# make histgram of CBF values for each subject\n",
    "makecbf_hist = Node(Function(input_names=['cbf_vol'], \n",
    "                             output_names=['cbf_hist'], \n",
    "                             function=make_histogram), \n",
    "                    name = 'makecbf_hist')\n",
    "\n",
    "checkcoreg_cbf = Node(Function(input_names=['ref','anat'],\n",
    "                               output_names=['coreg_file'],\n",
    "                               function=create_cbfcoreg_plot), \n",
    "                      name='checkcoreg_cbf')\n",
    "\n",
    "checkcoreg_mni = Node(Function(input_names=['ref','anat'],\n",
    "                               output_names=['coreg_file'],\n",
    "                               function=create_cbfcoreg_plot), \n",
    "                      name='checkcoreg_mni')\n",
    "checkcoreg_mni.inputs.anat=template\n",
    "\n",
    "# Register subject's anatomy/CBF to the template\n",
    "reg_anat2mni = Node(FLIRT(output_type='NIFTI',\n",
    "                          reference=template),\n",
    "                    name='reg_anat2mni')\n",
    "\n",
    "reg_cbf2mni = Node(FLIRT(output_type='NIFTI',\n",
    "                         apply_xfm = True,\n",
    "                         reference=template,\n",
    "                         out_file='warped_cbf.nii'),\n",
    "                   name='reg_cbf2mni')\n",
    "\n",
    "# smooth cbf data\n",
    "cbf_smooth = Node(Smooth(fwhm=[6,6,6], \n",
    "                     implicit_masking=True), \n",
    "              name='smooth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a flow for preprocessing anat + asl volumes \n",
    "cbfpreproc = Workflow(name='cbfpreproc')\n",
    "\n",
    "# Connect all components of the preprocessing workflow\n",
    "cbfpreproc.connect([(infosource,selectfiles, [('subjid', 'subjid')]),\n",
    "                    (infosource,fssource, [('subjid','subject_id')]),\n",
    "                    (fssource,mri_convert, [('brainmask', 'in_file')]),\n",
    "                    (mri_convert,reorient_anat, [('out_file','in_file')]),\n",
    "                    (reorient_anat,binarize, [('out_file','in_file')]),\n",
    "                    (reorient_anat,reg_pw2anat, [('out_file','reference')]),\n",
    "                    (reorient_anat,reg_pd2anat, [('out_file','reference')]),\n",
    "                    (reorient_anat,checkcoreg_cbf, [('out_file','anat')]),\n",
    "                    (reorient_anat,reg_anat2mni, [('out_file','in_file')]),\n",
    "                    (reg_anat2mni,reg_cbf2mni, [('out_matrix_file','in_matrix_file')]),\n",
    "                    (reg_anat2mni,checkcoreg_mni, [('out_file','ref')]),\n",
    "                    (binarize,applyMask_pw, [('binary_file','mask_file')]),\n",
    "                    (binarize,applyMask_pd, [('binary_file','mask_file')]),\n",
    "                    \n",
    "                    (selectfiles,reorient_pw, [('pw_volume','in_file')]),\n",
    "                    (reorient_pw,reg_pw2anat, [('out_file','in_file')]),\n",
    "                    (reg_pw2anat,reg_pd2anat, [('out_matrix_file','in_matrix_file')]),\n",
    "                    (selectfiles,reorient_pd, [('pd_volume','in_file')]),\n",
    "                    (reorient_pd,reg_pd2anat, [('out_file','in_file')]),\n",
    "                    (reg_pw2anat,applyMask_pw, [('out_file','in_file')]),\n",
    "                    (applyMask_pw, quant_cbf_alsop, [('out_file','pw_volume')]),\n",
    "                    (reg_pd2anat,applyMask_pd, [('out_file','in_file')]),\n",
    "                    (applyMask_pd,quant_cbf_alsop, [('out_file','pd_volume')]),\n",
    "                    \n",
    "                    (quant_cbf_alsop,checkcoreg_cbf, [('cbf_volume','ref')]),\n",
    "                    (quant_cbf_alsop,reg_cbf2mni,[('cbf_volume','in_file')]),\n",
    "                    (reg_cbf2mni, cbf_smooth, [('out_file','in_files')]),\n",
    "                    \n",
    "                    (checkcoreg_cbf,datasink, [('coreg_file','CBF_anat_coreg')]),\n",
    "                    (checkcoreg_mni,datasink, [('coreg_file','MNI_anat_coreg')]),\n",
    "                    (cbf_smooth,datasink, [('smoothed_files','std_cbf')]),\n",
    "                    (reorient_anat,datasink, [('out_file','preproc_anat')]),\n",
    "                    (reg_anat2mni,datasink, [('out_file','std_anat')]),\n",
    "                    (reg_anat2mni,datasink, [('out_matrix_file','reg_mni_xform')]),\n",
    "                    (binarize,datasink, [('binary_file','brainmask')])                    \n",
    "                   ])\n",
    "cbfpreproc.base_dir = wkflow_dir\n",
    "cbfpreproc.write_graph(graph2use='flat')\n",
    "cbfpreproc.run('MultiProc', plugin_args={'n_procs': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bandpass_filter(in_file, lowpass, highpass, TR):\n",
    "    import numpy as np\n",
    "    import nibabel as nb\n",
    "    from os.path import abspath\n",
    "    from nipype.interfaces.afni.preprocess import Bandpass\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    out_file = 'func_filtered'\n",
    "    bp = Bandpass()\n",
    "    bp.inputs.highpass = highpass\n",
    "    bp.inputs.lowpass = lowpass\n",
    "    bp.inputs.in_file = in_file\n",
    "    bp.inputs.tr = TR\n",
    "    bp.inputs.out_file = out_file\n",
    "    bp.inputs.outputtype = 'NIFTI'\n",
    "    bp.run()\n",
    "    \n",
    "    out_file = abspath(out_file + '.nii')\n",
    "    return(out_file)\n",
    "\n",
    "def adjust_masks(masks):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from nipype.interfaces.freesurfer.model import Binarize\n",
    "    #pve0 = csf, pve1 = gm, pve2 = wm\n",
    "    \n",
    "    origvols = sorted(masks)\n",
    "    csf = origvols[0]\n",
    "    wm = origvols[2]\n",
    "    vols = []\n",
    "    \n",
    "    binary = Binarize()\n",
    "    binary.inputs.in_file = wm\n",
    "    binary.inputs.min = 0.5\n",
    "    binary.inputs.max = 2\n",
    "    binary.inputs.binary_file = 'WM_seg.nii'\n",
    "    binary.run()\n",
    "    wm_new = abspath(binary.inputs.binary_file)\n",
    "    vols.append(wm_new)\n",
    "    \n",
    "    binary2 = Binarize()\n",
    "    binary2.inputs.in_file = csf\n",
    "    binary2.erode = 1\n",
    "    binary2.inputs.min = 0.5\n",
    "    binary2.inputs.max = 2\n",
    "    binary2.inputs.binary_file = 'CSF_seg.nii'\n",
    "    binary2.run()\n",
    "    csf_new = abspath(binary2.inputs.binary_file)\n",
    "    vols.append(csf_new)\n",
    "    \n",
    "    return(vols)\n",
    "    \n",
    "def create_noise_matrix(vols_to_censor,motion_params,comp_noise):\n",
    "    from numpy import genfromtxt, zeros, column_stack, savetxt\n",
    "    from os import path\n",
    "    \n",
    "    motion = genfromtxt(motion_params, delimiter=None, dtype=None, skip_header=0)\n",
    "    comp_noise = genfromtxt(comp_noise, delimiter=None, dtype=None, skip_header=1)\n",
    "    censor_vol_list = genfromtxt(vols_to_censor, delimiter=None, dtype=None, skip_header=0)\n",
    "    \n",
    "    try:\n",
    "        c = censor_vol_list.size\n",
    "    except:\n",
    "        c = 0\n",
    "    \n",
    "    d=len(comp_noise)\n",
    "\n",
    "    if c > 1:\n",
    "        scrubbing = zeros((d,c),dtype=int)\n",
    "        for t in range(c):\n",
    "            scrubbing[censor_vol_list[t],t] = 1\n",
    "        noise_matrix = column_stack((motion,comp_noise,scrubbing))\n",
    "    elif c == 1:\n",
    "        scrubbing = zeros((d,c),dtype=int)\n",
    "        scrubbing[censor_vol_list] = 1\n",
    "        noise_matrix = column_stack((motion,comp_noise,scrubbing))\n",
    "    else:\n",
    "        noise_matrix = column_stack((motion,comp_noise))\n",
    "    \n",
    "    noise_file = 'noise_matrix.txt'\n",
    "    savetxt(noise_file, noise_matrix)\n",
    "    noise_filepath = path.abspath(noise_file)\n",
    "    \n",
    "    return(noise_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resting state preprocessing nodes\n",
    "\n",
    "# Trim the initial volumes\n",
    "trim = Node(Trim(begin_index=vols_to_trim), name='trim')\n",
    "\n",
    "# Realign each volume to first volume: in_file; out_file, par_file\n",
    "realign = Node(MCFLIRT(out_file='realigned_func.nii',\n",
    "                       ref_vol=0), \n",
    "               name='realign')\n",
    "\n",
    "# Slice time correction: in_file, slice_time_corrected_file\n",
    "slicetime = Node(SliceTimer(time_repetition=rest_TR, \n",
    "                            interleaved=interleaved,\n",
    "                            slice_direction=slice_direction, \n",
    "                            out_file='stfunc.nii'), \n",
    "                    name='slicetime')\n",
    "\n",
    "# register the functional volumes to the subject space anat\n",
    "# inputs: in_file, reference; out_file out_matrix_file\n",
    "reg_func_to_anat = Node(FLIRT(out_matrix_file='xform.mat'),\n",
    "                        name='reg_func_to_anat')\n",
    "\n",
    "apply_reg_to_func = Node(FLIRT(apply_xfm=True, \n",
    "                               out_file='warped_func.nii'),  \n",
    "                         name='apply_reg_to_func')\n",
    "\n",
    "# Apply binary mask to merged functional scan: in_file, mask_file; out_file\n",
    "mask_func = Node(ApplyMask(out_file='masked_func.nii'), \n",
    "                 name='mask_func')\n",
    "\n",
    "# Bandpass Filtering all rates are in Hz (1/TR or samples/second)\n",
    "bandpass = Node(name='bandpass', \n",
    "                interface=Function(input_names=['in_file','lowpass','highpass','TR'], \n",
    "                                   output_names=['out_file'],\n",
    "                                   function=bandpass_filter))\n",
    "bandpass.inputs.lowpass = lowpass_freq\n",
    "bandpass.inputs.highpass = highpass_freq\n",
    "bandpass.inputs.TR = rest_TR\n",
    "\n",
    "# Artifact detection for scrubbing/motion assessment\n",
    "art = Node(ArtifactDetect(mask_type='file',\n",
    "                          parameter_source='FSL',\n",
    "                          norm_threshold=1.0, #mutually exclusive with rotation and translation thresh\n",
    "                          zintensity_threshold=3,\n",
    "                          use_differences=[True, False]),\n",
    "           name='art')\n",
    "\n",
    "# Segment structural scan\n",
    "segment = Node(FAST(no_bias=True, \n",
    "                    segments=True, \n",
    "                    number_classes=3), \n",
    "               name='segment')\n",
    "\n",
    "# Fix the segmentations\n",
    "fix_confs = Node(name='fix_confs',\n",
    "                 interface=Function(input_names=['masks'], \n",
    "                                    output_names=['vols'],\n",
    "                                    function=adjust_masks))\n",
    "# actually run compcor\n",
    "compcor = Node(CompCor(merge_method='none'), \n",
    "               name='compcor')\n",
    "\n",
    "# Create a denoising mask with compcor + motion\n",
    "noise_mat = Node(name='noise_mat', interface=Function(input_names=['vols_to_censor','motion_params','comp_noise'],\n",
    "                                                      output_names=['noise_filepath'], \n",
    "                                                      function=create_noise_matrix))\n",
    "\n",
    "# Denoise the data\n",
    "denoise = Node(GLM(out_res_name='denoised_residuals.nii', \n",
    "                   out_data_name='denoised_func.nii'), \n",
    "               name='denoise')\n",
    "\n",
    "# Register to MNI space\n",
    "reg_rest2standard = Node(FLIRT(), \n",
    "                         name = 'reg_rest2standard')\n",
    "\n",
    "# Apply the transform to all volumes\n",
    "rest_applyXform = Node(FLIRT(), \n",
    "                       name = 'rest_applyXform')\n",
    "# Smooth the data\n",
    "def brightthresh(func):\n",
    "    import nibabel as nib\n",
    "    from numpy import median, where\n",
    "    \n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    func_nifti1 = nib.load(func)\n",
    "    func_data = func_nifti1.get_data()\n",
    "    func_data = func_data.astype(float)\n",
    "    \n",
    "    brain_values = where(func_data > 0)\n",
    "    median_thresh = median(brain_values)\n",
    "    bright_thresh = 0.75 * median_thresh\n",
    "    \n",
    "    return(bright_thresh)\n",
    "    \n",
    "brightthresh = Node(Function(input_names=['func'],\n",
    "                             output_names=['bright_thresh'],\n",
    "                             function=brightthresh),\n",
    "                    name='brightthresh')\n",
    "smooth = Node(SUSAN(fwhm=smoothing_kernel),\n",
    "              name='smooth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_coreg_plot(epi,anat):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    from nipype.interfaces.nipy.preprocess import Trim\n",
    "    \n",
    "    epiVol = 'firstVol.nii'\n",
    "    trim = Trim()\n",
    "    trim.inputs.in_file = epi\n",
    "    trim.inputs.out_file = epiVol\n",
    "    trim.inputs.end_index = 1\n",
    "    trim.inputs.begin_index = 0\n",
    "    trim.run()\n",
    "    \n",
    "    coreg_filename='coregistration.png'\n",
    "    display = plotting.plot_anat(epiVol, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'coregistration to anatomy')\n",
    "    display.add_edges(anat)\n",
    "    display.savefig(coreg_filename) \n",
    "    display.close()\n",
    "    coreg_file = abspath(coreg_filename)\n",
    "    \n",
    "    return(coreg_file)\n",
    "\n",
    "def check_mask_coverage(epi,brainmask):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    from nipype.interfaces.nipy.preprocess import Trim\n",
    "    \n",
    "    epiVol = 'firstVol.nii'\n",
    "    trim = Trim()\n",
    "    trim.inputs.in_file = epi\n",
    "    trim.inputs.out_file = epiVol\n",
    "    trim.inputs.end_index = 1\n",
    "    trim.inputs.begin_index = 0\n",
    "    trim.run()\n",
    "    \n",
    "    maskcheck_filename='maskcheck.png'\n",
    "    display = plotting.plot_anat(epiVol, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'check brainmask coverage')\n",
    "    display.add_contours(brainmask,levels=[.5], colors='r')\n",
    "    display.savefig(maskcheck_filename) \n",
    "    display.close()\n",
    "    checkmask_file = abspath(maskcheck_filename)\n",
    "    \n",
    "    return(checkmask_file)\n",
    "    \n",
    "make_coreg_img = Node(Function(input_names=['epi','anat'],\n",
    "                                         output_names=['coreg_file'],\n",
    "                                         function=create_coreg_plot),\n",
    "                      name='make_coreg_img')\n",
    "\n",
    "make_checkmask_img = Node(Function(input_names=['epi','brainmask'],\n",
    "                                         output_names=['maskcheck_file'],\n",
    "                                         function=check_mask_coverage),\n",
    "                          name='make_checkmask_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# workflow\n",
    "restpreproc = Workflow(name='restpreproc')\n",
    "restpreproc.connect([(infosource,selectfiles,[('subjid','subjid')]),\n",
    "                     (infosource,structgrabber,[('subjid','subjid')]),\n",
    "                     (structgrabber, reg_func_to_anat,[('proc_anat','reference')]),\n",
    "                     \n",
    "                     (selectfiles,reorient_func,[('rest','in_file')]),\n",
    "                     (reorient_func,trim,[('out_file','in_file')]),\n",
    "                     (trim,realign,[('out_file','in_file')]),\n",
    "                     (realign, slicetime,[('out_file','in_file')]),\n",
    "                     (slicetime,reg_func_to_anat,[('slice_time_corrected_file','in_file')]),\n",
    "                     (slicetime,apply_reg_to_func,[('slice_time_corrected_file','in_file')]),\n",
    "                     (reg_func_to_anat,apply_reg_to_func,[('out_matrix_file','in_matrix_file')]),\n",
    "                     (apply_reg_to_func,mask_func,[('out_file','in_file')]),\n",
    "                     \n",
    "                     (mask_func,art,[('out_file','realigned_files')]),\n",
    "                     (realign,art,[('','realignment_parameters')]),\n",
    "                     (mask_func,compcor,[('out_file','realigned_file')]),\n",
    "                     (compcor,noise_mat,[('components_file','comp_noise')]),\n",
    "                     (art,noise_mat,[('outlier_files','vols_to_censor')]),\n",
    "                     (merge_motion,noise_mat,[('newmotion_params','motion_params')]),\n",
    "                     (noise_mat,denoise,[('noise_filepath','design')]),\n",
    "                     (mask_func,denoise,[('out_file','in_file')]),\n",
    "                     (denoise,bandpass,[('out_data','in_file')]),\n",
    "                     \n",
    "                     (mask_func,make_coreg_img,[('out_file','epi')]),\n",
    "                     (reorient_anat,make_coreg_img,[('out_file','anat')]),\n",
    "                     (mask_func,make_checkmask_img,[('out_file','epi')]),\n",
    "                     (binarize_anat,make_checkmask_img,[('binary_file','brainmask')]),\n",
    "                     \n",
    "                     (make_coreg_img,datasink,[('coreg_file','coregcheck_image')]),\n",
    "                     (make_checkmask_img,datasink,[('maskcheck_file','maskcheck_image')]),\n",
    "                     (mask_func, datasink,[('out_file','orig_merged_func')]),\n",
    "                     (reorient_anat,datasink,[('out_file','preproc_anat')]),\n",
    "                     (binarize_anat,datasink,[('binary_file','binarized_anat')]),\n",
    "                     (noise_mat,datasink,[('noise_filepath','full_noise_mat')]),\n",
    "                     (art,datasink,[('plot_files','art_plot_files')]),\n",
    "                     (bandpass,datasink,[('out_file','preproc_func')])        \n",
    "                    ])\n",
    "restpreproc.base_dir = workflow_dir\n",
    "restpreproc.write_graph(graph2use='flat')\n",
    "restpreproc.run('MultiProc', plugin_args={'n_procs': 2})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
